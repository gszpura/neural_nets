{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_chars = 142000\n",
    "\n",
    "with open('text2', 'r') as fd:\n",
    "    full_text = fd.read().lower()\n",
    "full_text = full_text[0:no_of_chars]\n",
    "\n",
    "vocab = set(full_text)\n",
    "int2char = dict(enumerate(vocab))\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "vocab_size = len(char2int)\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "print(\"Text lenght:\", len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers):\n",
    "        super(ModelLSTM, self).__init__()\n",
    "        output_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True)   \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, full_hidden):\n",
    "        out, full_hidden = self.lstm(x, full_hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        return out, full_hidden\n",
    "    \n",
    "    def init_full_hidden(self, batch_size):\n",
    "        hidden = torch.randn(self.n_layers, batch_size, self.hidden_size).to(device)\n",
    "        cell_state = torch.randn(self.n_layers, batch_size, self.hidden_size).to(device)\n",
    "        return (hidden, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_eq(text, no):\n",
    "    cnt = int(len(text) / no)\n",
    "    examples = [text[i:i+cnt] for i in range(0, len(text), cnt)]\n",
    "    if (no*cnt == len(text)):\n",
    "        return examples\n",
    "    else:\n",
    "        return examples[:-1]\n",
    "\n",
    "def produce_targets(examples):\n",
    "    targets = [ex[1:] for ex in examples]\n",
    "    inputs = [ex[:-1] for ex in examples]\n",
    "    return inputs, targets\n",
    "\n",
    "def translate_to_int(examples):\n",
    "    translated = [list(map(lambda ch: char2int[ch], ex)) for ex in examples]\n",
    "    return translated\n",
    "\n",
    "def translate_to_char(examples):\n",
    "    translated = [''.join(list(map(lambda i: int2char[i], ex))) for ex in examples]\n",
    "    return translated\n",
    "\n",
    "def one_hot_encode(examples):\n",
    "    features = np.zeros((len(examples), len(examples[0]), len(char2int)), dtype=np.float32)\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        for pos in range(len(examples[i]) - 1):\n",
    "            features[i, pos, examples[i][pos]] = 1\n",
    "    return features\n",
    "\n",
    "def to_model_format(inputs):\n",
    "    if isinstance(inputs, str):\n",
    "        inputs = [inputs]\n",
    "    trans_inputs = translate_to_int(inputs)\n",
    "    encoded = one_hot_encode(trans_inputs)\n",
    "    encoded_tensor = torch.from_numpy(encoded)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "no_of_examples = 64\n",
    "batch_size = examples_per_batch = 32\n",
    "lr = 0.0048\n",
    "\n",
    "no_of_batches = int(no_of_examples / examples_per_batch)\n",
    "\n",
    "examples = split_eq(full_text, no_of_examples)\n",
    "chars_per_example = len(examples[0])\n",
    "inputs, targets = produce_targets(examples)\n",
    "trans_inputs = translate_to_int(inputs)\n",
    "trans_targets = translate_to_int(targets)\n",
    "\n",
    "batches = []\n",
    "\n",
    "for i in range(no_of_batches):\n",
    "    input_seq = one_hot_encode(trans_inputs[i*examples_per_batch:(i+1)*examples_per_batch])\n",
    "    target_seq = torch.Tensor(trans_targets[i*examples_per_batch:(i+1)*examples_per_batch])\n",
    "    batches.append((torch.from_numpy(input_seq), target_seq))\n",
    "\n",
    "print(\"No of examples/No of data parts:\", no_of_examples)\n",
    "print(\"No of batches:\", no_of_batches)\n",
    "print(\"Examples per batch:\", examples_per_batch)\n",
    "print(\"Chars per example:\", chars_per_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(char2int)\n",
    "model = ModelLSTM(input_size=dict_size, hidden_size=36, n_layers=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1700\n",
    "counter = 0\n",
    "print_every = 50\n",
    "\n",
    "t_start = perf_counter()\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    counter += 1\n",
    "    for batch in batches:\n",
    "        h = model.init_full_hidden(batch_size)\n",
    "        model.zero_grad()\n",
    "        inp, target = batch\n",
    "        inp, target = inp.to(device), target.to(device)\n",
    "        output, h = model(inp, h)\n",
    "        loss = criterion(output, target.view(-1).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if counter%print_every == 0:\n",
    "        print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "              \"Loss: {:.6f}...\".format(loss.item()))\n",
    "        t_stop = perf_counter()\n",
    "        print(\"Time elasped:\", t_stop - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(device, model, full_hidden, input_string):\n",
    "    encoded_input = to_model_format(input_string)\n",
    "    out, hidden = model(encoded_input.to(device), full_hidden)\n",
    "\n",
    "    # choosing one with highest probability\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "\n",
    "def run_model(device, model, starting_seq, size=50):\n",
    "    model.eval()\n",
    "    seq = starting_seq.lower()\n",
    "    h = model.init_full_hidden(1)\n",
    "    for _ in range(size):\n",
    "        char, h = predict_next(device, model, h, seq)\n",
    "        seq += char\n",
    "    return ''.join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_model(device, model, 'A great and advanced society has ', 250)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./lstm_gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some results:\n",
    "\n",
    "Epoch: 2000/2000... Loss: 1.196766... 36/3 12800/32/16\n",
    "\"a great and advanced society has eopr doass moaddyr oolot  oorloo ,awn ooloa sahr aots aots loild ooloa sahr aots ooloa sahr aots loisd  oorsoa  oor,oart- eogr ooloo ,awn ooloa sahr aots loisd  oorsoa  oor,oart- eogr ooloo ,awn ooloa sahr aots loisd  oorsoa  oor,oart- eogr ooloo ,aw\"\n",
    "\n",
    "Epoch 1500/1500 Loss: 1.50 36/3 13200/16/16\n",
    "a great and advanced society has euft rult  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld  uedetiig tueld \n",
    "\n",
    "Epoch 2250/2250 Loss: 1.350470...13200/16/16\n",
    "a great and advanced society has euft ruotd tuutcoeddt  ueteel,s iutt rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rult rul\n",
    "\n",
    "Epoch: 3000/3000... Loss: 1.262259...13200/16/16\n",
    "a great and advanced society has eeftetg noubd tuet iutt rutttttutl lundetde rult rult rult rult nuuts iuttrrltt tuet eugttnitd eugtrnttrrln., ,uev tuet iuttrrtttttuudtt nuuts iuttrrltt tuet eugttnitd eugtrnttrrln., ,uev tuet iuttrrtttttuudtt nuuts iuttrrltt tuet eugttnitd eugtrnttr\n",
    "\n",
    "Epoch: 4000/4000... Loss: 1.187211...13200/16/16\n",
    "a great and advanced society has eeftetc  updu mm  feudrpling tuek tuetging tuet iugttnitg tuek tuelgn tftet  eenrton  ueielc  umdiilt  eentingtnrtnmtnnttrmm iftet  uede duoicg  umiill ,uifct mettoyt ruttttmunt rult nuutt  uede,drtmrr lfnitd eufc mf tuutdamdiagdtn tftet  eefrritdtyn\n",
    "\n",
    "Epoch 4500\n",
    "a great and advanced society has eeftetc  umdli,g lengyn.,irdnt ruots tuet iugttn tutkoetle  eerroitdeudttl npulrnn,c luyttnuuld ,uef eugrrstautd efteldn,trowttn tuetging tuet lundetde suo gupdepgisg,r relltruusd ymuls iitdouddtrrtlunl ,peodet iutt ruttttmunt rill oeg  ueielc  pmolc\n",
    "\n",
    "Epoch 5000\n",
    "a great and advanced society has eeftetc  umdiilt  iedtmnreli ruld tpetcoiddtt nuuts ,peodlttretct tuek ,feedaggttrrn  peotlo tiedd nuuusd nfurr npuftu teedtm, audlist  imdieitg tuuklynn,, ,uefette,,n,n nerttrnct nuuts ipt relct uudrend mmt iettott uid tmenc  peotdetti nfwwo raoldr \n",
    "\n",
    "Epoch 5500\n",
    "a great and advanced society has eeftetci teed nmumv  uedrtlunn yuu rfldttrttmt tftetl  ppict,i mmtt relct yiult reltnrnnitd eufc efaed-neniesc ,uef tuet iugttnitg tuekg,n mettoyt roasr  uebi ddotttn tfetri gpetteidg,,  ueditg rill oeg  ueielcs niutdoiddttmnnytn afdetiyg.m guedct nu\n",
    "\n",
    "Epoch 6200\n",
    "a great and advanced society has eeftetci tteutdoild yuu rfldntnrt uutr lpnte riolet ,pe dmuitggt wuttteugt rill oet iutt rotlln tuutlatd,y ,ee gmer teesm  feidtawd nuutr upd nfuwt uudring iutr upv ncuct..iiddtm mutt yfutdeer.. tuutllm siuddtt,tawiells yuu rfodd  uudrsna rdlsndns rf\n",
    "\n",
    "Epoch 6200 + 1700\n",
    "a great and advanced society has eufr tuek nfurtt tuet huo sdiit  feudtprpmesrlct eettert  cewdternttrrnmawd  etr iuttrrmtwue- iudrnlett neutd iotsetl  mp gopdluande reotgitgtmln spond ietcielg  imgleem,,\" 2uea\"fy nmutu nuutt rult ,uef tuet iu tvendttr ncu foedm,l,r reokgtnwt neudlt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
